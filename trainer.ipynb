{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install evaluate datasets transformers torch transformers[torch] SentencePiece rouge_score bleu bert-score squad sacrebleu sacremoses tqdm pypdfium2 spacy unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, Seq2SeqTrainer, Seq2SeqTrainingArguments, get_linear_schedule_with_warmup,pipeline\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset,Dataset\n",
    "import os\n",
    "from evaluate import load\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pypdfium2 as pdfium\n",
    "import re\n",
    "from spacy.lang.en import English\n",
    "from unstructured.cleaners.core import group_broken_paragraphs, replace_unicode_quotes, clean, clean_non_ascii_chars, remove_punctuation\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"asset\",\"ratings\")\n",
    "print(dataset)\n",
    "dataset1 = load_dataset(\"asset\")\n",
    "print(dataset1)\n",
    "train_x = dataset['full']['original']\n",
    "train_y = dataset['full']['simplification']\n",
    "validation_x = dataset1['validation']['original']\n",
    "validation_y = dataset1['validation']['simplifications']\n",
    "test_x = dataset1['test']['original']\n",
    "test_y = dataset1['test']['simplifications']\n",
    "\n",
    "train_df = pd.DataFrame({\n",
    "    'source_text': train_x,\n",
    "    'target_text': train_y\n",
    "})\n",
    "eval_df = pd.DataFrame({\n",
    "    'source_text': validation_x,\n",
    "    'target_text': validation_y\n",
    "})\n",
    "test_df = pd.DataFrame({\n",
    "    'source_text': test_x,\n",
    "    'target_text': test_y\n",
    "})\n",
    "# Add the prefix to source_text\n",
    "train_df['source_text'] = \"simplify this sentence: \" + train_df['source_text']\n",
    "\n",
    "eval_df['source_text'] = \"simplify this sentence: \" + eval_df['source_text']\n",
    "\n",
    "test_df['source_text'] = \"simplify this sentence: \" + test_df['source_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Train DataFrame:\")\n",
    "for index, row in train_df.head().iterrows():\n",
    "    print(f\"Index: {index}\")\n",
    "    print(f\"Source Text: {row['source_text']}\")\n",
    "    print(f\"Target Text: {row['target_text']}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"Eval DataFrame:\")\n",
    "for index, row in eval_df.head().iterrows():\n",
    "    print(f\"Index: {index}\")\n",
    "    print(f\"Source Text: {row['source_text']}\")\n",
    "    print(f\"Target Text: {row['target_text']}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"Test DataFrame:\")\n",
    "for index, row in test_df.head().iterrows():\n",
    "    print(f\"Index: {index}\")\n",
    "    print(f\"Source Text: {row['source_text']}\")\n",
    "    print(f\"Target Text: {row['target_text']}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"t5-small\"  # Change to the desired T5 model size\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "train_encodings = tokenizer(train_df['source_text'].tolist() , max_length=512, truncation=True, padding=True, return_tensors=\"pt\" )\n",
    "train_labels = tokenizer(train_df['target_text'].tolist() , max_length=512, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "validation_encodings = tokenizer(eval_df['source_text'].tolist() , max_length=512, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "validation_labels = tokenizer(eval_df['target_text'].tolist() , max_length=512, truncation=True, padding=True, return_tensors=\"pt\" )\n",
    "\n",
    "test_encodings = tokenizer(test_df['source_text'].tolist() , max_length=512, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "test_labels = tokenizer(test_df['target_text'].tolist() , max_length=512, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "train_dataset = Dataset.from_dict({\"input_ids\": train_encodings[\"input_ids\"], \"labels\": train_labels[\"input_ids\"]})\n",
    "validation_dataset = Dataset.from_dict({\"input_ids\": validation_encodings[\"input_ids\"], \"labels\": validation_labels[\"input_ids\"]})\n",
    "test_dataset = Dataset.from_dict({\"input_ids\": test_encodings[\"input_ids\"], \"labels\": test_labels[\"input_ids\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"t5-small\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/T5_small\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=4,\n",
    "    # per_device_eval_batch_size=1,\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=1e-4,\n",
    "    push_to_hub=False,\n",
    "    save_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    optimizers = (optimizer,None)\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
